{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.31. アフィン変換(スキュー)\n",
    "\n",
    "(1)アフィン変換を用いて、出力(1)のようなX-sharing(dx = 30)画像を作成せよ。\n",
    "\n",
    "(2)アフィン変換を用いて、出力2のようなY-sharing(dy = 30)画像を作成せよ。\n",
    "\n",
    "(3)アフィン変換を用いて、出力3のような幾何変換した(dx = 30, dy = 30)画像を作成せよ。\n",
    "\n",
    "このような画像はスキュー画像と呼ばれ、画像を斜め方向に伸ばした画像である。\n",
    "\n",
    "出力(1)の場合、x方向にdxだけ引き伸ばした画像はX-sharingと呼ばれる。\n",
    "\n",
    "出力(2)の場合、y方向にdyだけ引き伸ばした画像はY-sharingと呼ばれる。\n",
    "\n",
    "それぞれ次式のアフィン変換で実現できる。\n",
    "ただし、元画像のサイズがh x wとする。\n",
    "\n",
    "```bash\n",
    "(1) X-sharing                  (2) Y-sharing\n",
    "   a = dx / h                     a = dy / w\n",
    "\n",
    "  x'       1 a tx    x           x'       1 0 tx    x\n",
    "[ y' ] = [ 0 1 ty ][ y ]       [ y' ] = [ a 1 ty ][ y ]\n",
    "  1        0 0  1    1           1        0 0  1    1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Affine\n",
    "def affine(img, dx=30, dy=30):\n",
    "  H, W, C = img.shape\n",
    "\n",
    "  # Affine hyper parameters\n",
    "  a = 1.\n",
    "  b = dx / H\n",
    "  c = dy / W\n",
    "  d = 1.\n",
    "  tx = 0.\n",
    "  ty = 0.\n",
    "\n",
    "  # prepare temporary\n",
    "  _img = np.zeros((H+2, W+2, C), dtype=np.float32)\n",
    "\n",
    "  # insert image to center of temporary\n",
    "  _img[1:H+1, 1:W+1] = img\n",
    "\n",
    "  # prepare affine image temporary\n",
    "  H_new = np.ceil(dy + H).astype(np.int16)\n",
    "  W_new = np.ceil(dx + W).astype(np.int16)\n",
    "  out = np.zeros((H_new, W_new, C), dtype=np.float32)\n",
    "\n",
    "  # preprare assigned index\n",
    "  x_new = np.tile(np.arange(W_new), (H_new, 1))\n",
    "  y_new = np.arange(H_new).repeat(W_new).reshape(H_new, -1)\n",
    "\n",
    "  # prepare inverse matrix for affine\n",
    "  adbc = a * d - b * c\n",
    "  x = np.round((d * x_new  - b * y_new) / adbc).astype(np.int16) - tx + 1\n",
    "  y = np.round((-c * x_new + a * y_new) / adbc).astype(np.int16) - ty + 1\n",
    "\n",
    "  x = np.minimum(np.maximum(x, 0), W+1).astype(np.int16)\n",
    "  y = np.minimum(np.maximum(y, 0), H+1).astype(np.int16)\n",
    "\n",
    "  # assign value from original to affine image\n",
    "  out[y_new, x_new] = _img[y, x]\n",
    "  out = out.astype(np.uint8)\n",
    "\n",
    "  return out\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "\n",
    "# Affine\n",
    "out = affine(img, dx=30, dy=30)\n",
    "cv2.imwrite(\"training_IMG/training_31.png\", out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.32. フーリエ変換\n",
    "\n",
    "二次元離散フーリエ変換(DFT)を実装し、*imori.jpg*をグレースケール化したものの周波数のパワースペクトルを表示せよ。\n",
    "また、逆二次元離散フーリエ変換(IDFT)で画像を復元せよ。\n",
    "\n",
    "二次元離散フーリエ変換(DFT: Discrete Fourier Transformation)とはフーリエ変換の画像に対する処理方法である。\n",
    "\n",
    "通常のフーリエ変換はアナログ信号や音声などの連続値かつ一次元を対象に周波数成分を求める計算処理である。\n",
    "\n",
    "一方、ディジタル画像は[0,255]の離散値をとり、かつ画像はHxWの二次元表示であるので、二次元離散フーリエ変換が行われる。\n",
    "\n",
    "二次元離散フーリエ変換(DFT)は次式で計算される。\n",
    "\n",
    "<!--\n",
    "```bash\n",
    "K = 0:W, l = 0:H, 入力画像をI として\n",
    "G(k,l) = Sum_{y=0:H-1, x=0:W-1} I(x,y) exp( -2pi * j * (kx/W + ly/H)) / sqrt(H * W)\n",
    "```\n",
    "-->\n",
    "\n",
    "K = [0, W-1], l = [0, H-1], 入力画像を I として\n",
    "\n",
    "<img src=\"assets/dft_equ.png\" width=\"500\">\n",
    "\n",
    "ここでは画像をグレースケール化してから二次元離散フーリエ変換を行え。\n",
    "\n",
    "パワースペクトルとは Gは複素数で表されるので、Gの絶対値を求めることである。\n",
    "今回のみ画像表示の時はパワースペクトルは[0,255]にスケーリングせよ。\n",
    "\n",
    "逆二次元離散フーリエ変換(IDFT: Inverse DFT)とは周波数成分Gから元の画像を復元する手法であり、次式で定義される。\n",
    "\n",
    "<!--\n",
    "```bash\n",
    "x = 0:W, y = 0:H  として\n",
    "I(x,y) = Sum_{l=0:H-1, k=0:W-1} G(k,l) exp( 2pi * j * (kx/W + ly/H)) / sqrt(H * W)\n",
    "```\n",
    "-->\n",
    "x = [0, W-1], y = [0, H-1] として\n",
    "\n",
    "<img src=\"assets/idft_equ.png\" width=\"500\" >\n",
    "\n",
    "上が定義式ですがexp(j)は複素数の値をとってしまうので、実際にコードにするときはぜ下式のように絶対値を使います。\n",
    "\n",
    "<img src=\"assets/idct_equ2.png\" width=\"500\" >\n",
    "\n",
    "シンプルに全部for文で回すと128^4の計算になるので、時間がかかってしまいます。numpyをうまく活用すれば計算コストを減らすことができます。（解答は128^2まで減らしました。）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "K, L = 128, 128\n",
    "channel = 3\n",
    "\n",
    "def DFT(img):\n",
    "    H, W, _ = img.shape\n",
    "    G = np.zeros((L,K,channel), dtype=np.complex128)\n",
    "\n",
    "    # オリジナルの画像に対応する2次元の座標を作成\n",
    "    x = np.tile(np.arange(W),(H,1))\n",
    "    y = np.arange(H).repeat(W).reshape(H,-1)\n",
    "\n",
    "# ========================================================\n",
    "# x = np.tile(np.arange(4), (3, 1))\n",
    "# print(x)\n",
    "# Output:\n",
    "# [[0 1 2 3]\n",
    "#  [0 1 2 3]\n",
    "#  [0 1 2 3]]\n",
    "\n",
    "# y = np.arange(3).repeat(4).reshape(3, -1)\n",
    "# print(y)\n",
    "# Output:\n",
    "# [[0 0 0 0]\n",
    "#  [1 1 1 1]\n",
    "#  [2 2 2 2]]\n",
    "# ========================================================\n",
    "\n",
    "    # DFTの実装\n",
    "    for c in range(channel):\n",
    "        for l in range(L): # 画像の各行に対して処理を行う\n",
    "            for k in range(K): # 画像の各列に対して処理を行う\n",
    "                G[l,k,c] = np.sum(img[..., c]*np.exp(-2j*np.pi*(x*k / K+y*l / L))) / np.sqrt(K*L)\n",
    "    return G\n",
    "\n",
    "def IDFT(G):\n",
    "    H, W, _ = G.shape\n",
    "    out = np.zeros((H,W,channel), dtype=np.float32)\n",
    "\n",
    "    # オリジナルの画像に対応する2次元の座標を作成\n",
    "    x = np.tile(np.arange(W),(H,1))\n",
    "    y = np.arange(H).repeat(W).reshape(H,-1)\n",
    "\n",
    "    # IDFTの実装\n",
    "    for c in range(channel):\n",
    "        for l in range(H): # 画像の各行に対して処理を行う\n",
    "            for k in range(W): # 画像の各列に対して処理を行う\n",
    "                out[l,k,c] = np.abs(np.sum(G[..., c]*np.exp(2j*np.pi*(x*k / W+y*l / H)))) / np.sqrt(W*H)\n",
    "\n",
    "    # クリッピング\n",
    "    out = np.clip(out, 0, 255)\n",
    "    out = out.astype(np.uint8)\n",
    "\n",
    "    return out\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "\n",
    "# DFT\n",
    "G = DFT(img)\n",
    "\n",
    "# Save absolute value of DFT result as an image\n",
    "G_abs = (np.abs(G) / np.abs(G).max() * 255).astype(np.uint8)\n",
    "cv2.imwrite(\"training_IMG/training_32_dft.png\", G_abs)\n",
    "\n",
    "# IDFT\n",
    "out = IDFT(G)\n",
    "cv2.imwrite(\"training_IMG/training_32_idft.png\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.33. フーリエ変換　ローパスフィルタ\n",
    "\n",
    "*imori.jpg*をグレースケール化したものをDFTし、ローパスフィルタを通してIDFTで画像を復元せよ。\n",
    "\n",
    "DFTによって得られた周波数成分は左上、右上、左下、右下に近いほど低周波数の成分を含んでいることになり、中心に近いほど高周波成分を示す。\n",
    "\n",
    "![](assets/lpf.png)\n",
    "\n",
    "画像における高周波成分とは色が変わっている部分（ノイズや輪郭など）を示し、低周波成分とは色があまり変わっていない部分（夕日のグラデーションなど）を表す。\n",
    "\n",
    "ここでは、高周波成分をカットし、低周波成分のみを通す**ローパスフィルタ**を実装せよ。\n",
    "\n",
    "ここでは低周波数の中心から高周波までの距離をrとすると0.5rまでの成分を通すとする。\n",
    "\n",
    "※ ローパスフィルタ：信号処理において特定の頻度以下の信号は通過させ、それ以上の頻度の信号を遮断するフィルタのこと\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "K, L = 128, 128\n",
    "channel = 3\n",
    "\n",
    "def LPF(img, ratio=0.5):\n",
    "  H, W, _ = img.shape\n",
    "\n",
    "  # 位置の入れ替え、これによって低周波が中心に来るようにする。\n",
    "  _img = np.zeros_like(img)\n",
    "  _img[:H//2,:W//2] = img[H//2:,W//2:]\n",
    "  _img[:H//2,W//2:] = img[H//2:,:W//2]\n",
    "  _img[H//2:,:W//2] = img[:H//2,W//2:]\n",
    "  _img[H//2:,W//2:] = img[:H//2,:W//2]\n",
    "\n",
    "  # 中心からの距離を計算する\n",
    "  x = np.tile(np.arange(W),(H,1))\n",
    "  y = np.arange(H).repeat(W).reshape(H,-1)\n",
    "  _x = x - W // 2\n",
    "  _y = y - H // 2\n",
    "  r = np.sqrt(_x**2 + _y**2)\n",
    "\n",
    "  mask = np.ones((H,W), dtype=np.float32)\n",
    "  mask[r>(W//2*ratio)] = 0\n",
    "  mask = np.repeat(mask,channel).reshape(H,W,channel)\n",
    "\n",
    "  # フィルタリング実行\n",
    "  _img *= mask\n",
    "\n",
    "  # 元の配置に戻す\n",
    "  img[:H//2,:W//2] = _img[H//2:,W//2:]\n",
    "  img[:H//2,W//2:] = _img[H//2:,:W//2]\n",
    "  img[H//2:,:W//2] = _img[:H//2,W//2:]\n",
    "  img[H//2:,W//2:] = _img[:H//2,:W//2]\n",
    "\n",
    "  return img\n",
    "\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "\n",
    "# DFT\n",
    "G = DFT(img)\n",
    "\n",
    "# LPF\n",
    "G = LPF(G)\n",
    "\n",
    "# IDFT\n",
    "out = IDFT(G)\n",
    "out = np.clip(out, 0, 255).astype(np.uint8)\n",
    "\n",
    "cv2.imwrite(\"training_IMG/training_33.png\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.34. フーリエ変換　ハイパスフィルタ\n",
    "\n",
    "*imori.jpg*をグレースケール化したものをDFTし、ハイパスフィルタを通してIDFTで画像を復元せよ。\n",
    "\n",
    "ここでは、低周波成分をカットし、高周波成分のみを通す**ハイパスフィルタ**を実装せよ。\n",
    "\n",
    "ここでは低周波数の中心から高周波までの距離をrとすると0.1rからの成分を通すとする。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "K, L = 128, 128\n",
    "channel = 1\n",
    "\n",
    "def HPF(img, ratio=0.5):\n",
    "  H, W, _ = img.shape\n",
    "\n",
    "  # 位置の入れ替え、これによって低周波が中心に来るようにする。\n",
    "  _img = np.zeros_like(img)\n",
    "  _img[:H//2,:W//2] = img[H//2:,W//2:]\n",
    "  _img[:H//2,W//2:] = img[H//2:,:W//2]\n",
    "  _img[H//2:,:W//2] = img[:H//2,W//2:]\n",
    "  _img[H//2:,W//2:] = img[:H//2,:W//2]\n",
    "\n",
    "  # 中心からの距離を計算する\n",
    "  x = np.tile(np.arange(W),(H,1))\n",
    "  y = np.arange(H).repeat(W).reshape(H,-1)\n",
    "  _x = x - W // 2\n",
    "  _y = y - H // 2\n",
    "  r = np.sqrt(_x**2 + _y**2)\n",
    "\n",
    "  mask = np.ones((H,W), dtype=np.float32)\n",
    "  mask[r < (W//2*ratio)] = 0\n",
    "  mask = np.repeat(mask,channel).reshape(H,W,channel)\n",
    "\n",
    "  # フィルタリング実行\n",
    "  _img *= mask\n",
    "\n",
    "  # 元の配置に戻す\n",
    "  img[:H//2,:W//2] = _img[H//2:,W//2:]\n",
    "  img[:H//2,W//2:] = _img[H//2:,:W//2]\n",
    "  img[H//2:,:W//2] = _img[:H//2,W//2:]\n",
    "  img[H//2:,W//2:] = _img[:H//2,:W//2]\n",
    "\n",
    "  return img\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "\n",
    "# グレースケール化\n",
    "gray = 0.2126*img[...,2] + 0.7152*img[..., 1] + 0.0722*img[..., 0]\n",
    "gray = np.expand_dims(gray, axis=-1)\n",
    "\n",
    "# DFT\n",
    "G = DFT(gray)\n",
    "\n",
    "# HPF\n",
    "G = HPF(G)\n",
    "\n",
    "# IDFT\n",
    "out = IDFT(G)\n",
    "\n",
    "cv2.imwrite(\"training_IMG/training_34.png\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.35. フーリエ変換　バンドパスフィルタ\n",
    "\n",
    "*imori.jpg*をグレースケール化したものをDFTし、バンドパスフィルタを通してIDFTで画像を復元せよ。\n",
    "\n",
    "ここでは、低周波成分と高周波成分の中間の周波数成分のみを通す**バンドパスフィルタ**を実装せよ。\n",
    "\n",
    "ここでは低周波数の中心から高周波までの距離をrとすると0.1rから0.5rまでの成分を通すとする。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "K, L = 128, 128\n",
    "channel = 1\n",
    "\n",
    "def BPF(img,ratio_min=0.1,ratio_max=0.5):\n",
    "  H, W, _ = img.shape\n",
    "\n",
    "  # 位置の入れ替え、これによって低周波が中心に来るようにする。\n",
    "  _img = np.zeros_like(img)\n",
    "  _img[:H//2,:W//2] = img[H//2:,W//2:]\n",
    "  _img[:H//2,W//2:] = img[H//2:,:W//2]\n",
    "  _img[H//2:,:W//2] = img[:H//2,W//2:]\n",
    "  _img[H//2:,W//2:] = img[:H//2,:W//2]\n",
    "\n",
    "  # 中心からの距離を計算する\n",
    "  x = np.tile(np.arange(W),(H,1))\n",
    "  y = np.arange(H).repeat(W).reshape(H,-1)\n",
    "  _x = x - W // 2\n",
    "  _y = y - H // 2\n",
    "  r = np.sqrt(_x**2 + _y**2)\n",
    "\n",
    "  mask = np.ones((H,W), dtype=np.float32)\n",
    "  mask[(r < (W//2*ratio_min)) | (r > (W//2*ratio_max))] = 0\n",
    "  mask = np.repeat(mask,channel).reshape(H,W,channel)\n",
    "\n",
    "  # フィルタリング実行\n",
    "  _img *= mask\n",
    "\n",
    "  # 元の配置に戻す\n",
    "  img[:H//2,:W//2] = _img[H//2:,W//2:]\n",
    "  img[:H//2,W//2:] = _img[H//2:,:W//2]\n",
    "  img[H//2:,:W//2] = _img[:H//2,W//2:]\n",
    "  img[H//2:,W//2:] = _img[:H//2,:W//2]\n",
    "\n",
    "  return img\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "\n",
    "# グレースケール化\n",
    "gray = 0.2126*img[...,2] + 0.7152*img[..., 1] + 0.0722*img[..., 0]\n",
    "gray = np.expand_dims(gray, axis=-1)\n",
    "\n",
    "# DFT\n",
    "G = DFT(gray)\n",
    "\n",
    "# BPF\n",
    "G = BPF(G)\n",
    "\n",
    "# IDFT\n",
    "out = IDFT(G)\n",
    "\n",
    "cv2.imwrite(\"training_IMG/training_35.png\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.36. JPEG圧縮 (Step.1)離散コサイン変換\n",
    "\n",
    "*imori.jpg*をグレースケール化し離散コサイン変換を行い、逆離散コサイン変換を行え。\n",
    "\n",
    "離散コサイン変換(DCT: Discrete Cosine Transformation)とは、次式で定義される周波数変換の一つである。\n",
    "\n",
    "<img src=\"assets/dct_equ.png\" width=\"600\" >\n",
    "\n",
    "<!--\n",
    "```bash\n",
    "T = 8\n",
    "F(u,v) = 2 / T * C(u)C(v) * Sum_{y=0:T-1} Sum_{x=0:T-1} f(x,y) cos((2x+1)u*pi/2T) cos((2y+1)v*pi/2T)\n",
    "```\n",
    "-->\n",
    "\n",
    "逆離散コサイン変換(IDCT: Inverse Discrete Cosine Transformation)とは離散コサイン変換の逆（復号）であり、次式で定義される。\n",
    "\n",
    "ここでいう K は復元時にどれだけ解像度を良くするかを決定するパラメータである。\n",
    "\n",
    "K = Tの時は、DCT係数を全部使うのでIDCT後の解像度は最大になるが、Kが１や２などの時は復元に使う情報量（DCT係数）が減るので解像度が下がる。これを適度に設定することで、画像の容量を減らすことができる。\n",
    "\n",
    "<img src=\"assets/idct_equ.png\" width=\"600\">\n",
    "\n",
    "<!--\n",
    "```bash\n",
    "T = 8\n",
    "K = 8\n",
    "f(x,y) = 2 / T * C(x)C(y) * Sum_{u=0:K-1} Sum_{v=0:K-1} F(u,v) cos((2x+1)u*pi/2T) cos((2y+1)v*pi/2T)\n",
    "```\n",
    "-->\n",
    "\n",
    "ここでは画像を8x8ずつの領域に分割して、各領域で以上のDCT, IDCTを繰り返すことで、jpeg符号に応用される。\n",
    "今回も同様に8x8の領域に分割して、DCT, IDCTを行え。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "T, K = 8, 8\n",
    "channel = 1\n",
    "\n",
    "# 重みを計算する関数\n",
    "def DCT_w(x,y,u,v):\n",
    "  cu = 1.\n",
    "  cv = 1.\n",
    "  if u == 0:\n",
    "    cu /= np.sqrt(2)\n",
    "  if v == 0:\n",
    "    cv /= np.sqrt(2)\n",
    "  theta = np.pi/(2*T)\n",
    "  return ((2*cu*cv/T)*np.cos((2*x+1)*u*theta)*np.cos((2*y+1)*v*theta))\n",
    "\n",
    "def DCT(img):\n",
    "  H, W, _ = img.shape\n",
    "  F = np.zeros((H,W,channel), dtype=np.float32)\n",
    "\n",
    "  # 画像を小さなブロックに分割した上で処理を施す\n",
    "  for c in range(channel):\n",
    "    for xi in range(0, H, T):\n",
    "      for yi in range(0, W, T):\n",
    "        for v in range(T):\n",
    "          for u in range(T):\n",
    "            for y in range(T):\n",
    "              for x in range(T):\n",
    "                F[v+yi,u+xi,c] += img[y+yi,x+xi,c]*DCT_w(x,y,u,v)\n",
    "  return F\n",
    "\n",
    "def IDCT(F):\n",
    "  H, W, _ = F.shape\n",
    "  out = np.zeros((H, W, channel), dtype=np.float32)\n",
    "\n",
    "  for c in range(channel):\n",
    "    for yi in range(0, H, T):\n",
    "      for xi in range(0, W, T):\n",
    "        for y in range(T):\n",
    "          for x in range(T):\n",
    "            for v in range(K):\n",
    "              for u in range(K):\n",
    "                out[y+yi,x+xi,c] += F[v+yi,u+xi,c]*DCT_w(x,y,u,v)\n",
    "\n",
    "  out = np.clip(out, 0, 255)\n",
    "  out = np.round(out).astype(np.uint8)\n",
    "\n",
    "  return out\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "\n",
    "# グレースケール化\n",
    "gray = 0.2126*img[...,2] + 0.7152*img[..., 1] + 0.0722*img[..., 0]\n",
    "gray = np.expand_dims(gray, axis=-1)\n",
    "\n",
    "# DCT\n",
    "G = DCT(gray)\n",
    "\n",
    "# IDCT\n",
    "out = IDCT(G)\n",
    "\n",
    "cv2.imwrite(\"training_IMG/training_36.png\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "100knock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
